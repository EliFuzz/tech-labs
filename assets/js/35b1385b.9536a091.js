"use strict";(self.webpackChunkclassic=self.webpackChunkclassic||[]).push([[4908],{48584:(n,t,e)=>{e.r(t),e.d(t,{assets:()=>x,contentTitle:()=>f,default:()=>k,frontMatter:()=>m,metadata:()=>a,toc:()=>v});const a=JSON.parse('{"id":"education/computer-science/algorithms/algo/k-nn","title":"k-NN","description":"k-NN","source":"@site/docs/education/01-computer-science/10-algorithms/04-algo/k-nn.mdx","sourceDirName":"education/01-computer-science/10-algorithms/04-algo","slug":"/education/computer-science/algorithms/algo/k-nn","permalink":"/tech-labs/docs/education/computer-science/algorithms/algo/k-nn","draft":false,"unlisted":false,"editUrl":"https://github.com/EliFuzz/tech-labs/docs/education/01-computer-science/10-algorithms/04-algo/k-nn.mdx","tags":[],"version":"current","frontMatter":{"title":"k-NN","description":"k-NN","hide_table_of_contents":true},"sidebar":"education","previous":{"title":"k-Means","permalink":"/tech-labs/docs/education/computer-science/algorithms/algo/k-means"},"next":{"title":"Knapsack Problem","permalink":"/tech-labs/docs/education/computer-science/algorithms/algo/knapsack-problem"}}');var i=e(86070),s=e(15658),r=e(52421),o=e(74610),c=e(42953);const l='package main\n\nimport (\n    "math"\n    "sort"\n)\n\ntype Point struct {\n    X float64\n    Y float64\n}\n\ntype ByDistance struct {\n    Points []Point\n    Target Point\n}\n\nfunc (bd ByDistance) Len() int {\n    return len(bd.Points)\n}\n\nfunc (bd ByDistance) Swap(i, j int) {\n    bd.Points[i], bd.Points[j] = bd.Points[j], bd.Points[i]\n}\n\nfunc (bd ByDistance) Less(i, j int) bool {\n    distI := math.Sqrt(math.Pow(bd.Points[i].X-bd.Target.X, 2) + math.Pow(bd.Points[i].Y-bd.Target.Y, 2))\n    distJ := math.Sqrt(math.Pow(bd.Points[j].X-bd.Target.X, 2) + math.Pow(bd.Points[j].Y-bd.Target.Y, 2))\n    return distI < distJ\n}\n\nfunc KNN(data []Point, target Point, k int) []Point {\n    sortedData := ByDistance{Points: data, Target: target}\n    sort.Sort(sortedData)\n    return sortedData.Points[:k]\n}\n',d="import java.util.ArrayList;\nimport java.util.Comparator;\nimport java.util.List;\n\nclass Point {\n\n  double x, y;\n\n  Point(double x, double y) {\n    this.x = x;\n    this.y = y;\n  }\n}\n\npublic class KNN {\n\n  static List<Point> KNN(List<Point> data, Point target, int k) {\n    data.sort(new ByDistance(target));\n    return data.subList(0, k);\n  }\n\n  static class ByDistance implements Comparator<Point> {\n\n    Point target;\n\n    ByDistance(Point target) {\n      this.target = target;\n    }\n\n    double distance(Point p) {\n      return Math.sqrt(Math.pow(p.x - target.x, 2) + Math.pow(p.y - target.y, 2));\n    }\n\n    public int compare(Point p1, Point p2) {\n      return Double.compare(distance(p1), distance(p2));\n    }\n  }\n}\n",h="class Point {\n  constructor(x, y) {\n    this.x = x;\n    this.y = y;\n  }\n}\n\nfunction distance(p1, p2) {\n  return Math.sqrt(Math.pow(p1.x - p2.x, 2) + Math.pow(p1.y - p2.y, 2));\n}\n\nfunction KNN(data, target, k) {\n  data.sort((a, b) => distance(a, target) - distance(b, target));\n  return data.slice(0, k);\n}\n",u="data class Point(val x: Double, val y: Double)\n\nclass KNN {\n    companion object {\n        fun knn(data: List<Point>, target: Point, k: Int): List<Point> {\n            return data.sortedBy { distance(it, target) }.take(k)\n        }\n\n        private fun distance(p1: Point, p2: Point): Double {\n            return Math.sqrt(Math.pow(p1.x - p2.x, 2.0) + Math.pow(p1.y - p2.y, 2.0))\n        }\n    }\n}\n",p="import math\n\nclass Point:\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n\ndef distance(p1, p2):\n    return math.sqrt((p1.x - p2.x) ** 2 + (p1.y - p2.y) ** 2)\n\ndef KNN(data, target, k):\n    sorted_data = sorted(data, key=lambda x: distance(x, target))\n    return sorted_data[:k]\n",g="#[derive(Debug)]\nstruct Point {\n    x: f64,\n    y: f64,\n}\n\nfn distance(p1: &Point, p2: &Point) -> f64 {\n    ((p1.x - p2.x).powi(2) + (p1.y - p2.y).powi(2)).sqrt()\n}\n\nfn knn(data: &[Point], target: &Point, k: usize) -> Vec<Point> {\n    let mut sorted_data = data.to_vec();\n    sorted_data.sort_by(|a, b| distance(a, target).partial_cmp(&distance(b, target)).unwrap());\n    sorted_data[..k].to_vec()\n}\n",b="class Point {\n  constructor(\n    public x: number,\n    public y: number,\n  ) {}\n}\n\nfunction distance(p1: Point, p2: Point): number {\n  return Math.sqrt(Math.pow(p1.x - p2.x, 2) + Math.pow(p1.y - p2.y, 2));\n}\n\nfunction KNN(data: Point[], target: Point, k: number): Point[] {\n  return data\n    .sort((a, b) => distance(a, target) - distance(b, target))\n    .slice(0, k);\n}\n",m={title:"k-NN",description:"k-NN",hide_table_of_contents:!0},f=void 0,x={},v=[{value:"Definition",id:"definition",level:2},{value:"Practice",id:"practice",level:2}];function j(n){const t={code:"code",h2:"h2",li:"li",p:"p",pre:"pre",ul:"ul",...(0,s.R)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.h2,{id:"definition",children:"Definition"}),"\n",(0,i.jsxs)(r.A,{queryString:"primary",children:[(0,i.jsx)(o.A,{value:"definition",label:"Definition",children:(0,i.jsx)(t.p,{children:"The k-Nearest Neighbors (k-NN) algorithm is a simple yet powerful supervised machine learning algorithm used for classification and regression tasks. It works by finding the k closest data points in the training set to a given input data point and then making predictions based on the labels or values of those neighboring points"})}),(0,i.jsx)(o.A,{value:"how",label:"Explanation",children:(0,i.jsx)(t.p,{children:"Select the number of neighbors (k) and specify a distance metric. Then, given an input data point, identify the k nearest neighbors using the chosen distance metric. For classification purposes, ascertain the majority class within the k neighbors and designate it as the predicted class for the input point. In regression tasks, compute the average (or weighted average) of the target values of the k neighbors, assigning it as the predicted value. Finally, return the predicted class or value based on the task at hand"})}),(0,i.jsx)(o.A,{value:"guidance",label:"Guidance",children:(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"Choose the value of k, which determines how many neighbors will be considered for prediction"}),"\n",(0,i.jsx)(t.li,{children:"Select a distance metric such as Euclidean distance or Manhattan distance"}),"\n",(0,i.jsxs)(t.li,{children:["For each data point in the dataset","\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"calculate the distance between the input data point and all other data points using the chosen distance metric"}),"\n",(0,i.jsx)(t.li,{children:"sort the distances in ascending order and select the k nearest neighbors"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["For classification","\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"determine the majority class among the k neighbors"}),"\n",(0,i.jsx)(t.li,{children:"assign this class as the predicted class for the input data point"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["For regression","\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"calculate the average (or weighted average) of the target values of the k neighbors"}),"\n",(0,i.jsx)(t.li,{children:"assign this value as the predicted value for the input data point"}),"\n"]}),"\n"]}),"\n"]})}),(0,i.jsx)(o.A,{value:"tips",label:"Tips",children:(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"choose an appropriate value of k based on the dataset size and complexity. A smaller k may lead to overfitting, while a larger k may lead to underfitting"}),"\n",(0,i.jsx)(t.li,{children:"experiment with different distance metrics to find the one that best fits the data distribution"}),"\n",(0,i.jsx)(t.li,{children:"scaling the features can improve the performance of the algorithm, especially when using distance-based metrics"}),"\n",(0,i.jsx)(t.li,{children:"consider using weighted voting for classification, where closer neighbors have a higher influence on the prediction"}),"\n"]})})]}),"\n",(0,i.jsx)(t.h2,{id:"practice",children:"Practice"}),"\n",(0,i.jsxs)(r.A,{queryString:"primary",children:[(0,i.jsx)(o.A,{value:"practice",label:"Practice",children:(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'knn_predict(input_point, training_data, k, task_type):\n    // Step 1: Calculate distances\n    distances = []\n    for point in training_data:\n        distance = calculate_distance(input_point, point)\n        distances.append((point, distance))\n\n    // Step 2: Sort distances\n    sorted_distances = sort(distances, by=distance_value)\n\n    // Step 3: Select k nearest neighbors\n    nearest_neighbors = sorted_distances[:k]\n\n    // Step 4: Perform prediction based on task type\n    if task_type == "classification":\n        predicted_class = majority_vote(nearest_neighbors)\n        return predicted_class\n    elif task_type == "regression":\n        predicted_value = calculate_average(nearest_neighbors)\n        return predicted_value\n\ncalculate_distance(point1, point2):\n    // Implementation of distance calculation (e.g., Euclidean, Manhattan)\n    // Returns the distance value\n\ndistance_value(element):\n    // Returns the distance value of the element (used for sorting)\n\nmajority_vote(neighbors):\n    // Step 5a: Count occurrences of each class\n    class_counts = {}\n    for neighbor in neighbors:\n        neighbor_class = neighbor[0].class\n        if neighbor_class in class_counts:\n            class_counts[neighbor_class] += 1\n        else:\n            class_counts[neighbor_class] = 1\n\n    // Step 5b: Find the class with the highest count\n    max_count = 0\n    majority_class = None\n    for cls, count in class_counts.items():\n        if count > max_count:\n            max_count = count\n            majority_class = cls\n    return majority_class\n\ncalculate_average(neighbors):\n    // Step 5: Calculate the average (or weighted average) of target values\n    total_value = 0\n    for neighbor in neighbors:\n        total_value += neighbor[0].value  // Assuming the value is stored in neighbor[0]\n    average_value = total_value / len(neighbors)\n    return average_value\n'})})}),(0,i.jsx)(o.A,{value:"solution",label:"Solution",children:(0,i.jsxs)(r.A,{queryString:"code",children:[(0,i.jsx)(o.A,{value:"go",label:"",attributes:{title:"Go Lang",className:"code_lang go m"},children:(0,i.jsx)(c.A,{language:"go",children:l})}),(0,i.jsx)(o.A,{value:"java",label:"",attributes:{title:"Java",className:"code_lang java m"},children:(0,i.jsx)(c.A,{language:"java",children:d})}),(0,i.jsx)(o.A,{value:"js",label:"",attributes:{title:"JavaScript",className:"code_lang js m"},children:(0,i.jsx)(c.A,{language:"js",children:h})}),(0,i.jsx)(o.A,{value:"kotlin",label:"",attributes:{title:"Kotlin",className:"code_lang kotlin m"},children:(0,i.jsx)(c.A,{language:"kotlin",children:u})}),(0,i.jsx)(o.A,{value:"python",label:"",attributes:{title:"Python",className:"code_lang python m"},children:(0,i.jsx)(c.A,{language:"python",children:p})}),(0,i.jsx)(o.A,{value:"rust",label:"",attributes:{title:"Rust",className:"code_lang rust m"},children:(0,i.jsx)(c.A,{language:"rust",children:g})}),(0,i.jsx)(o.A,{value:"ts",label:"",attributes:{title:"TypeScript",className:"code_lang ts m"},children:(0,i.jsx)(c.A,{language:"ts",children:b})})]})})]})]})}function k(n={}){const{wrapper:t}={...(0,s.R)(),...n.components};return t?(0,i.jsx)(t,{...n,children:(0,i.jsx)(j,{...n})}):j(n)}}}]);